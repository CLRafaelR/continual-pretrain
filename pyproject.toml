[tool.poetry]
name = "continual-pretrain"
version = "0.1.0"
description = ""
authors = ["Masataka Ogawa <ogawa.phiz@gmail.com>"]
license = "MIT"
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.11"
fsspec = "2024.3.1"
datasets = "^2.19.2"
accelerate = "^0.31.0"
aiohttp = "^3.9.5"
aiosignal = "^1.3.1"
annotated-types = "^0.7.0"
appdirs = "^1.4.4"
async-timeout = "^4.0.3"
attrs = "^23.2.0"
bitsandbytes = "^0.43.1"
certifi = "^2024.6.2"
charset-normalizer = "^3.3.2"
click = "^8.1.7"
deepspeed = "^0.14.2"
dill = "^0.3.8"
docker-pycreds = "^0.4.0"
docstring-parser = "^0.16"
filelock = "^3.14.0"
frozenlist = "^1.4.1"
gitdb = "^4.0.11"
gitpython = "^3.1.43"
hjson = "^3.1.0"
huggingface-hub = "^0.23.3"
idna = "^3.7"
jinja2 = "^3.1.4"
markdown-it-py = "^3.0.0"
markupsafe = "^2.1.5"
mdurl = "^0.1.2"
mpmath = "^1.3.0"
multidict = "^6.0.5"
multiprocess = "^0.70.16"
networkx = "^3.3"
ninja = "^1.11.1.1"
numpy = "^1.26.4"
nvidia-ml-py = "^12.555.43"
packaging = "^24.0"
pandas = "^2.2.2"
peft = "0.6.0"
protobuf = "<5.0.0"
psutil = "^5.9.8"
py-cpuinfo = "^9.0.0"
pyarrow = "^16.1.0"
pyarrow-hotfix = "^0.6"
pydantic = "^2.7.3"
pydantic-core = "^2.18.4"
pygments = "^2.18.0"
pynvml = "^11.5.0"
python-dateutil = "^2.9.0.post0"
pytz = "^2024.1"
pyyaml = "^6.0.1"
regex = "^2024.5.15"
requests = "^2.32.3"
rich = "^13.7.1"
safetensors = "^0.4.3"
scipy = "^1.13.1"
sentencepiece = "^0.2.0"
sentry-sdk = "^2.5.1"
setproctitle = "^1.3.3"
shtab = "^1.7.1"
six = "^1.16.0"
smmap = "^5.0.1"
sympy = "^1.12.1"
tokenizers = "^0.19.1"
tqdm = "^4.66.4"
transformers = "^4.41.2"
trl = "^0.9.4"
typing-extensions = "^4.12.2"
tyro = "^0.8.4"
tzdata = "^2024.1"
urllib3 = "^2.2.1"
wandb = "^0.17.1"
xxhash = "^3.4.1"
yarl = "^1.9.4"
omegaconf = "^2.3.0"
llama-cpp-python = { version = "^0.2.77", source = "llama_cpp_python_cu121" }
torch = { version = "^2.3.1+cu121", source = "torch_cu121" }
nvidia-cublas-cu12 = { version = "^12.1.3.1", source = "torch_cu121" }
nvidia-cuda-cupti-cu12 = { version = "^12.1.105", source = "torch_cu121" }
nvidia-cuda-nvrtc-cu12 = { version = "^12.1.105", source = "torch_cu121" }
nvidia-cuda-runtime-cu12 = { version = "^12.1.105", source = "torch_cu121" }
nvidia-cudnn-cu12 = { version = "^8.9.2.26", source = "torch_cu121" }
nvidia-cufft-cu12 = { version = "^11.0.2.54", source = "torch_cu121" }
nvidia-curand-cu12 = { version = "^10.3.2.106", source = "torch_cu121" }
nvidia-cusolver-cu12 = { version = "^11.4.5.107", source = "torch_cu121" }
nvidia-cusparse-cu12 = { version = "^12.1.0.106", source = "torch_cu121" }
nvidia-nccl-cu12 = { version = "^2.20.5", source = "torch_cu121" }
nvidia-nvtx-cu12 = { version = "^12.1.105", source = "torch_cu121" }
optimum = "^1.20.0"
tensorboard = "^2.17.0"
wheel = "^0.43.0"
pytorch-triton = { version = "^2.3.0", source = "torch_cu121" }

[tool.poetry.group.dev.dependencies]
black = "^24.4.2"
flake8 = "^7.0.0"
ipykernel = "^6.29.4"
ipywidgets = "^8.1.3"
seedir = "^0.4.2"
emoji = "^2.12.1"
nbformat = "^5.10.4"
nbclient = "^0.10.0"
nbconvert = "^7.16.4"


[[tool.poetry.source]]
name = "torch_cu121"
url = "https://download.pytorch.org/whl/cu121"
priority = "explicit"


[[tool.poetry.source]]
name = "llama_cpp_python_cu121"
url = "https://abetlen.github.io/llama-cpp-python/whl/cu121"
priority = "explicit"


[[tool.poetry.source]]
name = "torch_nightly_cu121"
url = "https://download.pytorch.org/whl/nightly/cu121/"
priority = "explicit"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
